{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feed-forwad neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These are the commonest type of neural network in pratical applications\n",
    "    - The first layer is the input and last layer is the output\n",
    "    - If there is more than one hidden layer, we call them \"deep\" neural network\n",
    "- They compute a series of transformations that change the similarities between cases\n",
    "    - The activities of the neurons in each layer are a non-linear function of the activities in the layer below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural network\n",
    "\n",
    "- These have directed cycles in their connection graph\n",
    "    - That means you can sometimes get back to where you started by following the arrows\n",
    "- They can have complicated dynamics and this make them very difficult to train\n",
    "    - There is a lot of interest at present in finding efficient ways of training recurrent nets\n",
    "- They are more biological realistic\n",
    "\n",
    "(Recurrent nets with multiple layers are just a special case that has some of hidden -> hidden connections missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks for modeling sequences\n",
    "\n",
    "- Recurrent neural networks are a very natural way to model sequential data\n",
    "    - They are equivalent to very deep nets with one hidden layer per time slice\n",
    "    - Except that they use the same weights at every time slice and they get input at every time slice\n",
    "- They have the ability to remember informationin their hidden state for a long time\n",
    "    - But it's very hard to train them to use this potential\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And example of what recurrent neural nets can now do (to whet your interest!)\n",
    "\n",
    "- Ilya  Sutskever (2011) trained a special type of recurrent neural net to predict the next character in sequence\n",
    "- After training for a long time on a string of half billion characters from English Wikipedia, he got it to generate new text\n",
    "    - Its generates by predicting the probability distribution for the next character from this distribution\n",
    "    - The next slide shows an example of the kind of text it generates. Notice how much it works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some text generated _one character at a time_  by Ilya Sutskever's recurrent neural network\n",
    "\n",
    "In 1974 Northern Denver had been\n",
    "overshadowed by CNL, and several Irish\n",
    "intelligence agencies in the Mediterranean\n",
    "region. However, on the Victoria, Kings\n",
    "Hebrew stated that Charles decided to\n",
    "escape during an alliance. The mansion\n",
    "house was completed in 1882, the second in\n",
    "its bridge are omitted, while closing is the\n",
    "proton reticulum composed below it aims,\n",
    "such that it is the blurring of appearing on\n",
    "any well-paid type of box printer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Symmetrically connected networks\n",
    "\n",
    "- These are like recurrent networks, the the connection between units are simmetrical (they have the same weight int both directions).\n",
    "    - John Hopfield (and others) realized that symmetric networks are much easier to analyze than recurrent networks\n",
    "    - They are also more restricted in what they can do, because the obey an energy function\n",
    "        - For example, they cannot model cycles\n",
    "        \n",
    "- Symmetrically connected nets without hidden units are called \"Hopfield nets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
